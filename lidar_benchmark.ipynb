{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lidar benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import yaml\n",
    "import glob\n",
    "import scipy.io as scio\n",
    "import random\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from evaluate import error\n",
    "from mmfi import make_dataset, make_dataloader\n",
    "from lidar_point_transformer import PointTransformerReg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S02 ['A01', 'A06', 'A07', 'A08', 'A10', 'A12', 'A15', 'A24', 'A25', 'A26']\n",
      "S03 ['A01', 'A06', 'A07', 'A08', 'A09', 'A10', 'A11', 'A12', 'A15', 'A16', 'A24', 'A25']\n",
      "S05 ['A01', 'A06', 'A07', 'A08', 'A09', 'A10', 'A11', 'A15', 'A16', 'A24', 'A25', 'A26']\n",
      "S06 ['A01', 'A07', 'A08', 'A10', 'A11', 'A12', 'A16', 'A24', 'A25', 'A26']\n",
      "S08 ['A01', 'A06', 'A08', 'A09', 'A10', 'A11', 'A12', 'A15', 'A16', 'A24', 'A26']\n",
      "S09 ['A01', 'A11', 'A12', 'A16', 'A24', 'A25', 'A26']\n",
      "S11 ['A01', 'A06', 'A07', 'A09', 'A10', 'A12', 'A16', 'A24', 'A25', 'A26']\n",
      "S12 ['A01', 'A08', 'A09', 'A10', 'A11', 'A12', 'A15', 'A16', 'A24', 'A25']\n",
      "S13 ['A01', 'A07', 'A08', 'A09', 'A10', 'A11', 'A12', 'A15', 'A16', 'A24']\n",
      "S14 ['A01', 'A06', 'A07', 'A08', 'A09', 'A10', 'A11', 'A12', 'A15', 'A16', 'A24', 'A26']\n",
      "S15 ['A01', 'A06', 'A07', 'A08', 'A09', 'A11', 'A15', 'A16', 'A24', 'A25', 'A26']\n",
      "S16 ['A01', 'A08', 'A09', 'A10', 'A12', 'A15', 'A16', 'A25', 'A26']\n",
      "S17 ['A01', 'A06', 'A07', 'A08', 'A09', 'A12', 'A15', 'A16', 'A24', 'A26']\n",
      "S18 ['A01', 'A06', 'A07', 'A08', 'A09', 'A10', 'A11', 'A12', 'A15', 'A16', 'A24', 'A26']\n",
      "S19 ['A01', 'A06', 'A08', 'A09', 'A10', 'A11', 'A12', 'A15', 'A16', 'A24', 'A25', 'A26']\n",
      "S21 ['A01', 'A06', 'A07', 'A08', 'A09', 'A10', 'A12', 'A16', 'A24', 'A25', 'A26']\n",
      "S23 ['A01', 'A06', 'A08', 'A09', 'A10', 'A11', 'A12', 'A15', 'A24', 'A25']\n",
      "S25 ['A01', 'A06', 'A07', 'A09', 'A10', 'A11', 'A12', 'A15', 'A16', 'A24', 'A25', 'A26']\n",
      "S26 ['A01', 'A06', 'A07', 'A08', 'A09', 'A10', 'A15', 'A16', 'A26']\n",
      "S27 ['A01', 'A06', 'A07', 'A08', 'A09', 'A10', 'A11', 'A12', 'A16', 'A24', 'A25', 'A26']\n",
      "S28 ['A01', 'A06', 'A07', 'A08', 'A09', 'A11', 'A12', 'A15', 'A24']\n",
      "S29 ['A01', 'A06', 'A07', 'A08', 'A09', 'A10', 'A11', 'A15', 'A25', 'A26']\n",
      "S30 ['A01', 'A06', 'A07', 'A08', 'A09', 'A10', 'A11', 'A12', 'A15', 'A25', 'A26']\n",
      "S31 ['A01', 'A06', 'A07', 'A08', 'A11', 'A12', 'A15', 'A16', 'A24', 'A25', 'A26']\n",
      "S32 ['A01', 'A06', 'A08', 'A09', 'A10', 'A11', 'A12', 'A15', 'A16', 'A24', 'A25', 'A26']\n",
      "S33 ['A01', 'A06', 'A07', 'A08', 'A09', 'A10', 'A11', 'A12', 'A15', 'A16', 'A24', 'A25', 'A26']\n",
      "S34 ['A01', 'A06', 'A07', 'A09', 'A10', 'A11', 'A12', 'A15', 'A26']\n",
      "S35 ['A01', 'A06', 'A07', 'A08', 'A09', 'A10', 'A11', 'A12', 'A15', 'A16', 'A24', 'A25', 'A26']\n",
      "S36 ['A01', 'A06', 'A08', 'A09', 'A15', 'A16', 'A24', 'A25']\n",
      "S37 ['A01', 'A06', 'A07', 'A08', 'A09', 'A10', 'A11', 'A12', 'A15', 'A16', 'A25', 'A26']\n",
      "S38 ['A01', 'A07', 'A08', 'A09', 'A11', 'A12', 'A15', 'A16', 'A24', 'A25', 'A26']\n",
      "S40 ['A01', 'A06', 'A07', 'A08', 'A09', 'A10', 'A11', 'A12', 'A15', 'A24', 'A25', 'A26']\n",
      "S04 ['A06', 'A07', 'A10', 'A11', 'A16', 'A24', 'A25']\n",
      "S07 ['A06', 'A07', 'A08', 'A09', 'A10', 'A11', 'A12', 'A15', 'A16', 'A24', 'A25']\n",
      "S20 ['A06', 'A07', 'A09', 'A10', 'A11', 'A16', 'A24', 'A25', 'A26']\n",
      "S22 ['A06', 'A07', 'A09', 'A10', 'A11', 'A12', 'A16', 'A24', 'A25', 'A26']\n",
      "S24 ['A06', 'A07', 'A08', 'A10', 'A11', 'A15', 'A16', 'A24', 'A25', 'A26']\n",
      "S39 ['A06', 'A07', 'A08', 'A09', 'A10', 'A11', 'A12', 'A15', 'A24', 'A25', 'A26']\n",
      "S01 ['A07', 'A10', 'A11', 'A12', 'A15', 'A16', 'A25', 'A26']\n",
      "S10 ['A07', 'A08', 'A12', 'A15', 'A16', 'A25', 'A26']\n",
      "/n\n",
      "S01 ['A01', 'A06', 'A08', 'A09', 'A24']\n",
      "S04 ['A01', 'A08', 'A09', 'A12', 'A15', 'A26']\n",
      "S07 ['A01', 'A26']\n",
      "S10 ['A01', 'A06', 'A09', 'A10', 'A11', 'A24']\n",
      "S20 ['A01', 'A08', 'A12', 'A15']\n",
      "S22 ['A01', 'A08', 'A15']\n",
      "S24 ['A01', 'A09', 'A12']\n",
      "S39 ['A01', 'A16']\n",
      "S06 ['A06', 'A09', 'A15']\n",
      "S09 ['A06', 'A07', 'A08', 'A09', 'A10', 'A15']\n",
      "S12 ['A06', 'A07', 'A26']\n",
      "S13 ['A06', 'A25', 'A26']\n",
      "S16 ['A06', 'A07', 'A11', 'A24']\n",
      "S38 ['A06', 'A10']\n",
      "S08 ['A07', 'A25']\n",
      "S19 ['A07']\n",
      "S23 ['A07', 'A16', 'A26']\n",
      "S32 ['A07']\n",
      "S36 ['A07', 'A10', 'A11', 'A12', 'A26']\n",
      "S11 ['A08', 'A11', 'A15']\n",
      "S25 ['A08']\n",
      "S34 ['A08', 'A16', 'A24', 'A25']\n",
      "S02 ['A09', 'A11', 'A16']\n",
      "S31 ['A09', 'A10']\n",
      "S15 ['A10', 'A12']\n",
      "S17 ['A10', 'A11', 'A25']\n",
      "S28 ['A10', 'A16', 'A25', 'A26']\n",
      "S21 ['A11', 'A15']\n",
      "S26 ['A11', 'A12', 'A24', 'A25']\n",
      "S05 ['A12']\n",
      "S29 ['A12', 'A16', 'A24']\n",
      "S27 ['A15']\n",
      "S30 ['A16', 'A24']\n",
      "S40 ['A16']\n",
      "S37 ['A24']\n",
      "S14 ['A25']\n",
      "S18 ['A25']\n",
      "S03 ['A26']\n"
     ]
    }
   ],
   "source": [
    "dataset_root = '/media/xinyan/My Passport/FYP/Data'\n",
    "with open('config.yaml', 'r') as fd:\n",
    "    config = yaml.load(fd, Loader=yaml.FullLoader)\n",
    "\n",
    "train_dataset, val_dataset = make_dataset(dataset_root, config)\n",
    "\n",
    "# rng_generator = torch.manual_seed(config['init_rand_seed'])\n",
    "# train_loader = make_dataloader(train_dataset, is_training=True, generator=rng_generator, **config['loader'])\n",
    "# val_loader = make_dataloader(val_dataset, is_training=False, generator=rng_generator, **config['loader'])\n",
    "\n",
    "# # TODO: Code for training or validation\n",
    "# sample = train_dataset[0]\n",
    "# print(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn_padd(batch):\n",
    "    '''\n",
    "    Padds batch of variable length\n",
    "\n",
    "    note: it converts things ToTensor manually here since the ToTensor transform\n",
    "    assume it takes in images rather than arbitrary tensors.\n",
    "    '''\n",
    "    ## get sequence lengths\n",
    "    # for t in batch:\n",
    "        # print(t['output'].type)\n",
    "    #     print(a)\n",
    "        # print(t[0].shape,t[1].shape)\n",
    "    kpts = []\n",
    "    [kpts.append(np.array(t['output'])) for t in batch]\n",
    "    kpts = torch.FloatTensor(np.array(kpts))\n",
    "\n",
    "    lengths = torch.tensor([t['input_lidar'].shape[0] for t in batch ])\n",
    "    ## padd\n",
    "    batch = [torch.Tensor(np.array(t['input_lidar'])) for t in batch ]\n",
    "    batch = torch.nn.utils.rnn.pad_sequence(batch)\n",
    "    ## compute mask\n",
    "    batch = batch.permute(1,0,2)\n",
    "    mask = (batch != 0)\n",
    "\n",
    "    return batch, kpts, lengths, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng_generator = torch.manual_seed(config['init_rand_seed'])\n",
    "train_loader = make_dataloader(train_dataset, is_training=True, generator=rng_generator, **config['loader'], collate_fn = collate_fn_padd)\n",
    "val_loader = make_dataloader(val_dataset, is_training=False, generator=rng_generator, **config['loader'], collate_fn = collate_fn_padd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1498, 3])\n",
      "torch.Size([32, 17, 3])\n",
      "torch.Size([32, 1462, 3])\n",
      "torch.Size([32, 17, 3])\n",
      "torch.Size([32, 1448, 3])\n",
      "torch.Size([32, 17, 3])\n"
     ]
    }
   ],
   "source": [
    "for i,data in enumerate(train_loader):\n",
    "    inputs, labels, length, mask = data\n",
    "    print(inputs.shape)\n",
    "    print(labels.shape)\n",
    "    if i == 2:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### creating a config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from configparser import ConfigParser\n",
    "\n",
    "#Get the configparser object\n",
    "config_object = ConfigParser()\n",
    "\n",
    "#Assume we need 2 sections in the config file, let's call them USERINFO and SERVERCONFIG\n",
    "config_object[\"Lidar\"] = {\n",
    "    'num_point': 1024, \n",
    "    'nblocks': 5, \n",
    "    'nneighbor': 16, \n",
    "    'num_class': 17*3, \n",
    "    'input_dim': 3\n",
    "}\n",
    "config_object[\"mmwave\"] = {\n",
    "    'nblocks': 5, \n",
    "    'nneighbor': 16, \n",
    "    'num_class': 17*3, \n",
    "    'input_dim': 5\n",
    "}\n",
    "\n",
    "#Write the above sections to config.ini file\n",
    "with open('model_config.yaml', 'w') as conf:\n",
    "    config_object.write(conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('model_config.yaml', 'r') as fd:\n",
    "        model_cfg = yaml.load(fd, Loader=yaml.FullLoader)\n",
    "lidar_cfg = model_cfg['lidar']\n",
    "model = PointTransformerReg(lidar_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 17, 3])\n"
     ]
    }
   ],
   "source": [
    "model = PointTransformerReg(lidar_cfg)\n",
    "# print(model)\n",
    "x = torch.rand(16, 1630, 3)\n",
    "y = model(x)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, tensor_loader, criterion1, criterion2, device):\n",
    "    model.eval()\n",
    "    test_mpjpe = 0\n",
    "    test_pampjpe = 0\n",
    "    test_mse = 0\n",
    "    for data in tqdm(tensor_loader):\n",
    "        inputs, labels, _, _ = data\n",
    "        inputs = inputs.to(device)\n",
    "        labels.to(device)\n",
    "        labels = labels.type(torch.FloatTensor)\n",
    "        outputs = model(inputs)\n",
    "        outputs = outputs.type(torch.FloatTensor)\n",
    "        outputs.to(device)\n",
    "        test_mse += criterion1(outputs,labels).item() * inputs.size(0)\n",
    "\n",
    "        outputs = outputs.detach().numpy()\n",
    "        labels = labels.detach().numpy()\n",
    "        \n",
    "        mpjpe, pampjpe = criterion2(outputs,labels)\n",
    "        test_mpjpe += mpjpe.item() * inputs.size(0)\n",
    "        test_pampjpe += pampjpe.item() * inputs.size(0)\n",
    "    test_mpjpe = test_mpjpe/len(tensor_loader.dataset)\n",
    "    test_pampjpe = test_pampjpe/len(tensor_loader.dataset)\n",
    "    test_mse = test_mse/len(tensor_loader.dataset)\n",
    "    print(\"mse: {:.8f}, mpjpe: {:.8f}, pampjpe: {:.8f}\".format(float(test_mse), float(test_mpjpe),float(test_pampjpe)))\n",
    "    return test_mpjpe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 966/966 [12:44<00:00,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse: 0.00396983, mpjpe: 0.09307124, pampjpe: 0.05865553\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.093071238341124"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_criterion = nn.MSELoss()\n",
    "test_criterion = error\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.load_state_dict(torch.load('./pre-train_weights/lidar_p2_random(1).pt',map_location='cuda:0'))\n",
    "model.to(device)\n",
    "test(\n",
    "    model=model,\n",
    "    tensor_loader= val_loader,\n",
    "    criterion1 = train_criterion,\n",
    "    criterion2 = test_criterion,\n",
    "    device=device\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, test_loader, num_epochs, learning_rate, train_criterion, test_criterion, device):\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate)\n",
    "    scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer,milestones=[20,40],gamma=0.1)\n",
    "    parameter_dir = './pre-train_weights/lidar_p2_cross_scene(1).pt'\n",
    "    best_test_mpjpe = 100\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "        epoch_accuracy = 0\n",
    "        for data in tqdm(train_loader):\n",
    "            inputs, labels, _, _ = data\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            labels = labels.type(torch.FloatTensor)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            outputs = outputs.to(device)\n",
    "            outputs = outputs.type(torch.FloatTensor)\n",
    "            loss = train_criterion(outputs,labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            epoch_loss += loss.item() * inputs.size(0)\n",
    "        epoch_loss = epoch_loss/len(train_loader.dataset)\n",
    "        print('Epoch: {}, Loss: {:.8f}'.format(epoch, epoch_loss))\n",
    "        if (epoch+1) % 5 == 0:\n",
    "            test_mpjpe = test(\n",
    "                model=model,\n",
    "                tensor_loader=test_loader,\n",
    "                criterion1 = train_criterion,\n",
    "                criterion2 = test_criterion,\n",
    "                device= device\n",
    "            )\n",
    "            if test_mpjpe <= best_test_mpjpe:\n",
    "                print(f\"best test mpjpe is:{test_mpjpe}\")\n",
    "                best_test_mpjpe = test_mpjpe\n",
    "                torch.save(model.state_dict(), parameter_dir)\n",
    "        scheduler.step()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3619/3619 [1:07:35<00:00,  1.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 0.03526332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3619/3619 [26:53<00:00,  2.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss: 0.01087625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3619/3619 [27:03<00:00,  2.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Loss: 0.00887579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3619/3619 [26:56<00:00,  2.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3, Loss: 0.00771079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3619/3619 [27:00<00:00,  2.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4, Loss: 0.00692958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1207/1207 [21:42<00:00,  1.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse: 0.02233060, mpjpe: 0.23249234, pampjpe: 0.12299502\n",
      "best test mpjpe is:0.2324923404030033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3619/3619 [26:55<00:00,  2.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5, Loss: 0.00637843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3619/3619 [26:51<00:00,  2.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6, Loss: 0.00595131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3619/3619 [27:00<00:00,  2.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7, Loss: 0.00557768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3619/3619 [26:53<00:00,  2.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8, Loss: 0.00531372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3619/3619 [26:56<00:00,  2.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9, Loss: 0.00505809\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1207/1207 [04:58<00:00,  4.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse: 0.01726981, mpjpe: 0.20504831, pampjpe: 0.10416801\n",
      "best test mpjpe is:0.20504830744685795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3619/3619 [26:52<00:00,  2.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10, Loss: 0.00485126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3619/3619 [26:53<00:00,  2.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11, Loss: 0.00467140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3619/3619 [26:54<00:00,  2.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12, Loss: 0.00449107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3619/3619 [26:55<00:00,  2.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13, Loss: 0.00436237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3619/3619 [26:55<00:00,  2.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14, Loss: 0.00423824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1207/1207 [04:55<00:00,  4.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse: 0.01630623, mpjpe: 0.20035326, pampjpe: 0.09747398\n",
      "best test mpjpe is:0.20035326128115896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3619/3619 [27:00<00:00,  2.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15, Loss: 0.00412353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3619/3619 [26:53<00:00,  2.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16, Loss: 0.00402966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3619/3619 [26:48<00:00,  2.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17, Loss: 0.00392630\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3619/3619 [26:50<00:00,  2.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 18, Loss: 0.00385875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3619/3619 [26:47<00:00,  2.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 19, Loss: 0.00376907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1207/1207 [04:57<00:00,  4.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse: 0.01579718, mpjpe: 0.19823503, pampjpe: 0.09242944\n",
      "best test mpjpe is:0.19823503404415757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3619/3619 [27:00<00:00,  2.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20, Loss: 0.00365124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3619/3619 [26:52<00:00,  2.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 21, Loss: 0.00364181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3619/3619 [26:51<00:00,  2.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 22, Loss: 0.00363546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3619/3619 [26:47<00:00,  2.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 23, Loss: 0.00362745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3619/3619 [26:45<00:00,  2.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 24, Loss: 0.00362451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1207/1207 [04:57<00:00,  4.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse: 0.01595038, mpjpe: 0.20000058, pampjpe: 0.09086569\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3619/3619 [26:54<00:00,  2.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 25, Loss: 0.00360904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3619/3619 [26:54<00:00,  2.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 26, Loss: 0.00360608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3619/3619 [26:40<00:00,  2.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 27, Loss: 0.00360750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3619/3619 [26:13<00:00,  2.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 28, Loss: 0.00358809\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3619/3619 [26:06<00:00,  2.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 29, Loss: 0.00359209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1207/1207 [04:52<00:00,  4.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse: 0.01513956, mpjpe: 0.19362519, pampjpe: 0.09265220\n",
      "best test mpjpe is:0.19362518565236703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3619/3619 [26:12<00:00,  2.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 30, Loss: 0.00357128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3619/3619 [26:46<00:00,  2.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 31, Loss: 0.00357862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3619/3619 [26:45<00:00,  2.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 32, Loss: 0.00357100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3619/3619 [26:51<00:00,  2.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 33, Loss: 0.00355368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3619/3619 [26:50<00:00,  2.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 34, Loss: 0.00356083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1207/1207 [04:57<00:00,  4.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse: 0.01518247, mpjpe: 0.19411357, pampjpe: 0.09175399\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3619/3619 [26:46<00:00,  2.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 35, Loss: 0.00355092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3619/3619 [26:49<00:00,  2.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 36, Loss: 0.00352739\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3619/3619 [26:53<00:00,  2.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 37, Loss: 0.00353558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3619/3619 [26:55<00:00,  2.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 38, Loss: 0.00353182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3619/3619 [26:51<00:00,  2.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 39, Loss: 0.00351145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1207/1207 [04:57<00:00,  4.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse: 0.01455618, mpjpe: 0.18921056, pampjpe: 0.09205666\n",
      "best test mpjpe is:0.18921055596469444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3619/3619 [26:54<00:00,  2.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 40, Loss: 0.00351562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3619/3619 [26:55<00:00,  2.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 41, Loss: 0.00350712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3619/3619 [26:50<00:00,  2.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 42, Loss: 0.00351914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3619/3619 [26:57<00:00,  2.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 43, Loss: 0.00350748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3619/3619 [26:59<00:00,  2.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 44, Loss: 0.00350346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1207/1207 [04:57<00:00,  4.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse: 0.01518479, mpjpe: 0.19406169, pampjpe: 0.09235285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3619/3619 [26:58<00:00,  2.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 45, Loss: 0.00350743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3619/3619 [26:51<00:00,  2.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 46, Loss: 0.00350507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3619/3619 [26:52<00:00,  2.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 47, Loss: 0.00350075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 1728/3619 [13:00<14:14,  2.21it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/xinyan/Desktop/MM-Fi/lidar_benchmark.ipynb Cell 17\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/xinyan/Desktop/MM-Fi/lidar_benchmark.ipynb#X22sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# model.load_state_dict(torch.load('./pre-train_weights/lidar_p1_random.pt'))\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/xinyan/Desktop/MM-Fi/lidar_benchmark.ipynb#X22sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m model\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/xinyan/Desktop/MM-Fi/lidar_benchmark.ipynb#X22sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m train(\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/xinyan/Desktop/MM-Fi/lidar_benchmark.ipynb#X22sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     model\u001b[39m=\u001b[39;49mmodel,\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/xinyan/Desktop/MM-Fi/lidar_benchmark.ipynb#X22sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     train_loader\u001b[39m=\u001b[39;49m train_loader,\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/xinyan/Desktop/MM-Fi/lidar_benchmark.ipynb#X22sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     test_loader\u001b[39m=\u001b[39;49m val_loader,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/xinyan/Desktop/MM-Fi/lidar_benchmark.ipynb#X22sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     num_epochs\u001b[39m=\u001b[39;49m \u001b[39m50\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/xinyan/Desktop/MM-Fi/lidar_benchmark.ipynb#X22sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     learning_rate\u001b[39m=\u001b[39;49m\u001b[39m1e-2\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/xinyan/Desktop/MM-Fi/lidar_benchmark.ipynb#X22sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     train_criterion \u001b[39m=\u001b[39;49m train_criterion,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/xinyan/Desktop/MM-Fi/lidar_benchmark.ipynb#X22sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     test_criterion \u001b[39m=\u001b[39;49m test_criterion,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/xinyan/Desktop/MM-Fi/lidar_benchmark.ipynb#X22sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     device\u001b[39m=\u001b[39;49mdevice\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/xinyan/Desktop/MM-Fi/lidar_benchmark.ipynb#X22sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m         )\n",
      "\u001b[1;32m/home/xinyan/Desktop/MM-Fi/lidar_benchmark.ipynb Cell 17\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, test_loader, num_epochs, learning_rate, train_criterion, test_criterion, device)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/xinyan/Desktop/MM-Fi/lidar_benchmark.ipynb#X22sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m labels \u001b[39m=\u001b[39m labels\u001b[39m.\u001b[39mtype(torch\u001b[39m.\u001b[39mFloatTensor)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/xinyan/Desktop/MM-Fi/lidar_benchmark.ipynb#X22sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/xinyan/Desktop/MM-Fi/lidar_benchmark.ipynb#X22sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m outputs \u001b[39m=\u001b[39m model(inputs)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/xinyan/Desktop/MM-Fi/lidar_benchmark.ipynb#X22sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m outputs \u001b[39m=\u001b[39m outputs\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/xinyan/Desktop/MM-Fi/lidar_benchmark.ipynb#X22sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m outputs \u001b[39m=\u001b[39m outputs\u001b[39m.\u001b[39mtype(torch\u001b[39m.\u001b[39mFloatTensor)\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Desktop/MM-Fi/lidar_point_transformer.py:134\u001b[0m, in \u001b[0;36mPointTransformerReg.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m--> 134\u001b[0m     points, _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbackbone(x)\n\u001b[1;32m    135\u001b[0m     res \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfc2(points\u001b[39m.\u001b[39mmean(\u001b[39m1\u001b[39m))\n\u001b[1;32m    136\u001b[0m     pkt \u001b[39m=\u001b[39m res\u001b[39m.\u001b[39mreshape(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m17\u001b[39m, \u001b[39m3\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Desktop/MM-Fi/lidar_point_transformer.py:113\u001b[0m, in \u001b[0;36mBackbone.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    111\u001b[0m xyz_and_feats \u001b[39m=\u001b[39m [(xyz, points)]\n\u001b[1;32m    112\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnblocks):\n\u001b[0;32m--> 113\u001b[0m     xyz, points \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransition_downs[i](xyz, points)\n\u001b[1;32m    114\u001b[0m     points \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransformers[i](xyz, points)[\u001b[39m0\u001b[39m]\n\u001b[1;32m    115\u001b[0m     xyz_and_feats\u001b[39m.\u001b[39mappend((xyz, points))\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Desktop/MM-Fi/lidar_point_transformer.py:53\u001b[0m, in \u001b[0;36mTransitionDown.forward\u001b[0;34m(self, xyz, points)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, xyz, points):\n\u001b[0;32m---> 53\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msa(xyz, points)\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Desktop/MM-Fi/pointnet_util.py:189\u001b[0m, in \u001b[0;36mPointNetSetAbstraction.forward\u001b[0;34m(self, xyz, points)\u001b[0m\n\u001b[1;32m    187\u001b[0m     new_xyz, new_points \u001b[39m=\u001b[39m sample_and_group_all(xyz, points)\n\u001b[1;32m    188\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 189\u001b[0m     new_xyz, new_points \u001b[39m=\u001b[39m sample_and_group(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnpoint, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mradius, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnsample, xyz, points, knn\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mknn)\n\u001b[1;32m    190\u001b[0m \u001b[39m# new_xyz: sampled points position data, [B, npoint, C]\u001b[39;00m\n\u001b[1;32m    191\u001b[0m \u001b[39m# new_points: sampled points data, [B, npoint, nsample, C+D]\u001b[39;00m\n\u001b[1;32m    192\u001b[0m new_points \u001b[39m=\u001b[39m new_points\u001b[39m.\u001b[39mpermute(\u001b[39m0\u001b[39m, \u001b[39m3\u001b[39m, \u001b[39m2\u001b[39m, \u001b[39m1\u001b[39m) \u001b[39m# [B, C+D, nsample,npoint]\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/MM-Fi/pointnet_util.py:115\u001b[0m, in \u001b[0;36msample_and_group\u001b[0;34m(npoint, radius, nsample, xyz, points, returnfps, knn)\u001b[0m\n\u001b[1;32m    113\u001b[0m B, N, C \u001b[39m=\u001b[39m xyz\u001b[39m.\u001b[39mshape\n\u001b[1;32m    114\u001b[0m S \u001b[39m=\u001b[39m npoint\n\u001b[0;32m--> 115\u001b[0m fps_idx \u001b[39m=\u001b[39m farthest_point_sample(xyz, npoint) \u001b[39m# [B, npoint]\u001b[39;00m\n\u001b[1;32m    116\u001b[0m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mempty_cache()\n\u001b[1;32m    117\u001b[0m new_xyz \u001b[39m=\u001b[39m index_points(xyz, fps_idx)\n",
      "File \u001b[0;32m~/Desktop/MM-Fi/pointnet_util.py:65\u001b[0m, in \u001b[0;36mfarthest_point_sample\u001b[0;34m(xyz, npoint)\u001b[0m\n\u001b[1;32m     63\u001b[0m device \u001b[39m=\u001b[39m xyz\u001b[39m.\u001b[39mdevice\n\u001b[1;32m     64\u001b[0m B, N, C \u001b[39m=\u001b[39m xyz\u001b[39m.\u001b[39mshape\n\u001b[0;32m---> 65\u001b[0m centroids \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mzeros(B, npoint, dtype\u001b[39m=\u001b[39;49mtorch\u001b[39m.\u001b[39;49mlong)\u001b[39m.\u001b[39;49mto(device)\n\u001b[1;32m     66\u001b[0m distance \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mones(B, N)\u001b[39m.\u001b[39mto(device) \u001b[39m*\u001b[39m \u001b[39m1e10\u001b[39m\n\u001b[1;32m     67\u001b[0m farthest \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mrandint(\u001b[39m0\u001b[39m, N, (B,), dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mlong)\u001b[39m.\u001b[39mto(device)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_criterion = nn.MSELoss()\n",
    "test_criterion = error\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# model.load_state_dict(torch.load('./pre-train_weights/lidar_p1_random.pt'))\n",
    "model.to(device)\n",
    "train(\n",
    "    model=model,\n",
    "    train_loader= train_loader,\n",
    "    test_loader= val_loader,\n",
    "    num_epochs= 50,\n",
    "    learning_rate=1e-2,\n",
    "    train_criterion = train_criterion,\n",
    "    test_criterion = test_criterion,\n",
    "    device=device\n",
    "        )\n",
    "\n",
    "\n",
    "# parameter_dir = './pre-train_weights/lidar_random_p1.pt'\n",
    "# torch.save(model.state_dict(), parameter_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_dir = './pre-train_weights/lidar_random_p1.pt'\n",
    "torch.save(model.state_dict(), parameter_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'modality': ['lidar'], 'scene': 'E01', 'subject': 'S02', 'action': 'A02', 'idx': 0, 'output': tensor([[ 0.0508,  0.6183,  2.8169],\n",
      "        [ 0.0190,  0.6544,  2.8812],\n",
      "        [ 0.0781,  0.6600,  2.8859],\n",
      "        [-0.0256,  0.6572,  3.0327],\n",
      "        [ 0.1287,  0.6689,  3.0403],\n",
      "        [-0.0733,  0.4787,  3.0638],\n",
      "        [ 0.1982,  0.5117,  3.2712],\n",
      "        [-0.3137,  0.3794,  3.2431],\n",
      "        [ 0.3910,  0.3150,  2.8655],\n",
      "        [-0.2314,  0.4967,  3.5834],\n",
      "        [ 0.2114,  0.3039,  2.2418],\n",
      "        [-0.0221,  0.0094,  2.9235],\n",
      "        [ 0.1611,  0.0140,  3.2860],\n",
      "        [-0.0179, -0.3970,  2.9418],\n",
      "        [ 0.1691, -0.4529,  3.3647],\n",
      "        [-0.0062, -0.8078,  3.2431],\n",
      "        [ 0.1699, -0.8288,  3.3098]]), 'input_lidar': array([[ 2.90777755,  0.07454614,  0.5344317 ],\n",
      "       [ 2.91734099,  0.03896374,  0.53596509],\n",
      "       [ 2.91168737,  0.00316235,  0.53494281],\n",
      "       ...,\n",
      "       [ 2.01373601, -0.24735571, -1.1397754 ],\n",
      "       [ 2.00200009, -0.27087188, -1.13472259],\n",
      "       [ 2.00108552, -0.29580361, -1.13623846]])}\n",
      "(1131, 3)\n"
     ]
    }
   ],
   "source": [
    "for i in train_dataset:\n",
    "    print(i)\n",
    "    print(i['input_lidar'].shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frame001.bin\n"
     ]
    }
   ],
   "source": [
    "frame = '/media/xinyan/My Passport/FYP/Data/E01/S02/A02/lidar/frame001.bin'\n",
    "_, mod = os.path.split(frame)\n",
    "print(mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "root_dir='/media/xinyan/My Passport/FYP/Data'\n",
    "data_list = glob.glob(root_dir+'/*/*/*/radar')\n",
    "data_list.sort()\n",
    "for old_folder in data_list:\n",
    "    new_folder = old_folder.replace('radar', 'mmwave')\n",
    "    os.rename(old_folder, new_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "root_dir='/home/xinyan/Desktop/FYP/Data'\n",
    "data_list = glob.glob(root_dir+'/*/*/*/radar/*.bin')\n",
    "data_list.sort()\n",
    "for old_file in data_list:\n",
    "    new_file = old_file.replace('/home/xinyan/Desktop/FYP/Data', '/media/xinyan/My Passport/FYP/Data')\n",
    "    frame = '/' + new_file.split('/')[-1]\n",
    "    new_folder = new_file.replace(frame, '')\n",
    "    if not os.path.exists(new_folder):\n",
    "        os.mkdir(new_folder)\n",
    "    shutil.move(old_file, new_file)\n",
    "# print(data_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "28ddce5f25a21a07ad483909600054997aecc68f738e66d709935411fdfc5bae"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
